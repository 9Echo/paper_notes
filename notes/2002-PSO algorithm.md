### PSO粒子群优化算法

**基本思想**

粒子群优化算法是在1995年由Eberhart博士和Kennedy博士一起提出的，它源于对鸟群捕食行为的研究。它的基本核心是利用群体中的个体对信息的共享从而使得整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的最优解。**设想这么一个场景：一群鸟进行觅食，而远处有一片玉米地，所有的鸟都不知道玉米地到底在哪里，但是它们知道自己当前的位置距离玉米地有多远。那么找到玉米地的最佳策略，也是最简单有效的策略就是是搜寻目前距离玉米地最近的鸟群的周围区域**。

在PSO中，每个优化问题的解都是搜索空间中的一只鸟，称之为“粒子”，而问题的最优解就对应为鸟群要寻找的“玉米地”。所有的粒子都具有一个位置向量（粒子在解空间的位置）和速度向量（决定下次飞行的方向和速度），并可以根据目标函数来计算当前的所在位置的适应值（fitness value），可以将其理解为距离“玉米地”的距离。在每次的迭代中，种群中的粒子除了根据**自身的“经验”（历史位置）**进行学习以外，还可以根据种群中**最优粒子的“经验”**来学习，从而确定下一次迭代时需要如何调整和改变飞行的方向和速度。就这样逐步迭代，最终整个种群的粒子就会逐步趋于最优解。

**算法框架**

　　**Step 1** 种群初始化：可以进行随机初始化或者根据被优化的问题设计特定的初始化方法，然后计算个体的适应值，从而选择出个体的局部最优位置向量 *Pbesti* 和种群的全局最优位置向量 *Gbest*。

　　**Step 2** 迭代设置：设置迭代次数 $g_{max}$，并令当前迭代次数 g=1；

　　**Step 3** 速度更新：根据速度向量迭代公式更新每个个体的速度向量；

　　**Step 4** 位置更新：根据位置向量迭代公式更新每个个体的位置向量；

　　**Step 5** 局部位置向量和全局位置向量更新：更新每个个体的 *Pbesti* 和种群的 *Gbest*；

　　**Step 6** 终止条件判断：判断迭代次数时都达到 $g_{max}$，如果满足，输出 *Gbest*；否则继续进行迭代，跳转至**Step 3**。

**速度向量迭代公式：**
$$
V_i = wV_i + c_1r_1(Pbest_i - X_i) + c_2r_2(Gbest-X_i)
$$
$w$ 为权重向量，取值在 [0,1] 之间，一般采用自适应取值，值越大表示 PSO 全局优化能力越强，迭代越深入，权重值递减，从而使得 PSO 有较强的局部优化能力。

$c_1$ 和 $c_2$ 是学习因子可以理解为加速度常数，一般取 [0,4] 之间。

$r_1$ 和 $r_2$ 是[0,1] 之间的随机数。

*Pbesti* 和 *Gbest* 分别代表粒子 i 的历史最佳位置向量和种群历史最佳位置向量。

**位置向量迭代公式：**
$$
X_i = X_i + V_i
$$
对于粒子群优化算法的运用，主要是对速度和位置向量迭代算子的设计。迭代算子是否有效将决定整个PSO算法性能的优劣，所以如何设计PSO的迭代算子是PSO算法应用的研究重点和难点。

还有自适应版本（Adaptive PSO）和离散版本（discrete）



目前来看，粒子群和遗传算法都有多目标的算法。不过遗传算法更多一些，因为粒子群算法更新个体需要全局最优个体，而对于多目标问题，全局最优是不存在的，只有帕累托最优。



粒子群优化主要是靠步长公式，一个是全局优化，一个是局部优化。只要针对这两点就行了。引入时间因素，随着时间变化调整两者的比例。引入个体因素，部分个体倾向于全局，部分个体倾向于局部。引入状态因素，当处于某种状态时优先局部，当某种状态优先全局。[捂脸]我只能说粒子群浑身都是破绽，能改的地方真是太多了

