## 多目标优化方法总结

### 基本方法概述

1. methods with a priori articulation of preferences：先验偏好

   > 基于先验偏好大致分为加权法和约束法，将多个目标标量化最终转化为单目标优化目标。缺点：单次运算并不能获得整个Pareto最优解集，并且权重值和约束参数难以通过理论说明是否合理。**（这种方法无法体现目标之间的竞争关系）**

   - Weighted global criterion method
   - Weighted sum method
   - Weighted min-max method
   - Lexicographic method
   - Goal programming methods
2. methods with a posteriori articulation of preferences：后验偏好

   > 由于目标之间的偏好因子无法确定，故优先生成一组折衷解，利用偏好信息从中确定最优解

   - 数学方法（精确解）
     - Physical programming
     - Normal boundary intersection (NBI) method
     - Normal constraint (NC) method
   - **近似算法（启发式&元启发式算法）**



**多目标进化算法（Multi-Objective Evolutionary Algorithm，MOEA）**

也叫智能优化算法、元启发式算法 meta-heuristics

> 可以根据是否**利用了Pareto支配关系**分为基于群体的方法、和基于Pareto的方法，其中基于群体的方法（如：VEGA）各个子群之间独立执行进化操作，对于单个子目标的最优解会被抛弃，这种方法基本被淘汰。

优点：单词运算可获得真个解集，且该解集具有良好的收敛性和多样性

缺点：但大部分算法内部应用了随机优化结构，具有一定的不确定性，所以可行解和最优解的偏离程度一般无法被估计。

- 自然进化类算法
  - **遗传算法（GA）衍生算法**
    
    - VEGA（Vector evaluated genetic algorithm）：无 Pareto 支配关系，各个子群之间独立执行进化操作
    
    - NSGA-II（Elitist Non-dominated Sorting Genetic Algorithms）：提出拥挤度距离度量、保留精英策略
    
    - MOGA：加入排序机制（基于pareto支配关系）
    
      - SPEA & SPEA-II（strength Pareto evolutionary algorithm）
    
      - MOEA/D：基于分解的思想（传统数学规划方法结合进化算法）
    
        ​		该算法将通近整个Pareto前沿面的问题分解为一定数量的单目标优化问题,然后用进化算法同时求解这些单目标优化问题. 算法维持一个由每个子问题的当前最优解组成的种群, 子问题之间的近邻关系定义为子问题权重向量之间的距离, 每个子问题的优化过程通过与其近邻子问题之间的进化操作来完成.该算法成功地将数学规划中常用的分解方法引入到进化多目标领域,而且可以直接采用进化算法求解单目标优化问题时的适应度分配和多样性保持策略。
    
    - PESA & PESA-II（Pareto encelope-based selection algorithm）
  - 差分进化算法
  - 免疫算法
    
    - NNIA：基于免疫克隆机制
    
      NNIA模拟了免疫响应中多样性抗体共生 、少数抗体激活的现象, 通过一种基于非支配邻域的个体选择方法, 只选择少数相对孤立的非支配个体作为活性抗体,根据活性抗体的拥挤程度进行比例克隆复制, 对克隆后的抗体群采用了有别于 GA 的重组操作和变异操作, 以此加强对当前Pareto 前沿面中较稀疏区域的搜索.
- 仿生类算法
  - **蚁群算法**（Multi-Objective Ant Colony Optimization, ACO) 2007年提出
  - **粒子群算法**（Multi-Objective Particle Swam Optimization, PSO）2002年提出，应用最为广泛
- 仿物类算法
  
  - **模拟退火算法**
- 人工搜索类算法
  - 禁忌搜索
  - 迭代局部搜索
  - 邻域搜索
- 人工神经网络算法
  - 监督式学习网络
  - 无监督式学习
  - 混合式学习
  - 联想式学习

一般接近实例的案例里面一般都涉及多种算法，先用元启发算法（智能优化算法）求得一个小范围的满意解，再用启发式或者精确算法找最优解，这样既提高效率又能有高质量结果。算法的混合可以发挥各自的优点，抵消其缺点，实现更好的性能。

### 常用算法介绍

#### ACO蚁群算法



