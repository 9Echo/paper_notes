## 多目标优化方法总结

### 基本方法概述

1. methods with a priori articulation of preferences：先验偏好

   > 基于先验偏好大致分为加权法和约束法，将多个目标标量化最终转化为单目标优化目标。缺点：单次运算并不能获得整个Pareto最优解集，并且权重值和约束参数难以通过理论说明是否合理。

   - Weighted global criterion method
   - Weighted sum method
   - Weighted min-max method
   - Lexicographic method
   - Goal programming methods
2. methods with a posteriori articulation of preferences：后验偏好

   > 由于目标之间的偏好因子无法确定，故优先生成一组折衷解，利用偏好信息从中确定最优解

   - 数学方法（精确解）
     - Physical programming
     - Normal boundary intersection (NBI) method
     - Normal constraint (NC) method
   - **近似算法（启发式&元启发式算法）**
3. methods with no articulation of preferences：没有表达偏好



**多目标进化算法（Multi-Objective Evolutionary Algorithm，MOEA）**

也叫智能优化算法、元启发式算法 meta-heuristics

> 可以根据是否**利用了Pareto支配关系**分为基于群体的方法、和基于Pareto的方法，其中基于群体的方法（如：VEGA）各个子群之间独立执行进化操作，对于单个子目标的最优解会被抛弃，这种方法基本被淘汰。

优点：单词运算可获得真个解集，且该解集具有良好的收敛性和多样性

缺点：但大部分算法内部应用了随机优化结构，具有一定的不确定性，所以可行解和最优解的偏离程度一般无法被估计。

- 自然进化类算法
  - **遗传算法（GA）衍生算法**
    - VEGA（Vector evaluated genetic algorithm）：无 Pareto 支配关系，各个子群之间独立执行进化操作
    
    - NSGA-II（Elitist Non-dominated Sorting Genetic Algorithms）：提出拥挤度距离度量
    
    - MOGA：加入排序机制
    
    - SPEA & SPEA-II（strength Pareto evolutionary algorithm）
    
    - MOEA/D：基于分解的思想（传统数学规划方法结合进化算法）
    
      该算法将通近整个Pareto前沿面的问题分解为一定数量的单目标优化问题,然后用进化算法同时求解这些单目标优化问题. 算法维持一个由每个子问题的当前最优解组成的种群, 子问题之间的近邻关系定义为子问题权重向量之间的距离, 每个子问题的优化过程通过与其近邻子问题之间的进化操作来完成.该算法成功地将数学规划中常用的分解方法引入到进化多目标领域,而且可以直接采用进化算法求解单目标优化问题时的适应度分配和多样性保持策略。
    
    - PESA & PESA-II（Pareto encelope-based selection algorithm）
  - 差分进化算法
  - 免疫算法
    
    - NNIA：基于免疫克隆机制
    
      NNIA模拟了免疫响应中多样性抗体共生 、少数抗体激活的现象, 通过一种基于非支配邻域的个体选择方法, 只选择少数相对孤立的非支配个体作为活性抗体,根据活性抗体的拥挤程度进行比例克隆复制, 对克隆后的抗体群采用了有别于 GA 的重组操作和变异操作, 以此加强对当前Pareto 前沿面中较稀疏区域的搜索.
- 仿生类算法
  - **蚁群算法**（Ant Colony Optimization, ACO) 1992年提出
  - **粒子群算法**（Particle Swam Optimization, PSO）1995年提出，应用最为广泛
- 仿物类算法
  
  - 模拟退火算法
- 人工搜索类算法
  - 禁忌搜索
  - 迭代局部搜索
  - 邻域搜索
- 人工神经网络算法
  - 监督式学习网络
  - 无监督式学习
  - 混合式学习
  - 联想式学习

一般接近实例的案例里面一般都涉及多种算法，先用元启发算法（智能优化算法）求得一个小范围的满意解，再用启发式或者精确算法找最优解，这样既提高效率又能有高质量结果。算法的混合可以发挥各自的优点，抵消其缺点，实现更好的性能。

### 常用算法介绍

#### 1. PSO粒子群优化算法

**基本思想**

粒子群优化算法是在1995年由Eberhart博士和Kennedy博士一起提出的，它源于对鸟群捕食行为的研究。它的基本核心是利用群体中的个体对信息的共享从而使得整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的最优解。**设想这么一个场景：一群鸟进行觅食，而远处有一片玉米地，所有的鸟都不知道玉米地到底在哪里，但是它们知道自己当前的位置距离玉米地有多远。那么找到玉米地的最佳策略，也是最简单有效的策略就是是搜寻目前距离玉米地最近的鸟群的周围区域**。

在PSO中，每个优化问题的解都是搜索空间中的一只鸟，称之为“粒子”，而问题的最优解就对应为鸟群要寻找的“玉米地”。所有的粒子都具有一个位置向量（粒子在解空间的位置）和速度向量（决定下次飞行的方向和速度），并可以根据目标函数来计算当前的所在位置的适应值（fitness value），可以将其理解为距离“玉米地”的距离。在每次的迭代中，种群中的粒子除了根据**自身的“经验”（历史位置）**进行学习以外，还可以根据种群中**最优粒子的“经验”**来学习，从而确定下一次迭代时需要如何调整和改变飞行的方向和速度。就这样逐步迭代，最终整个种群的粒子就会逐步趋于最优解。

**算法框架**

　　**Step 1** 种群初始化：可以进行随机初始化或者根据被优化的问题设计特定的初始化方法，然后计算个体的适应值，从而选择出个体的局部最优位置向量 *Pbesti* 和种群的全局最优位置向量 *Gbest*。

　　**Step 2** 迭代设置：设置迭代次数 $g_{max}$，并令当前迭代次数 g=1；

　　**Step 3** 速度更新：根据速度向量迭代公式更新每个个体的速度向量；

　　**Step 4** 位置更新：根据位置向量迭代公式更新每个个体的位置向量；

　　**Step 5** 局部位置向量和全局位置向量更新：更新每个个体的 *Pbesti* 和种群的 *Gbest*；

　　**Step 6** 终止条件判断：判断迭代次数时都达到 $g_{max}$，如果满足，输出 *Gbest*；否则继续进行迭代，跳转至**Step 3**。

**速度向量迭代公式：**
$$
V_i = wV_i + c_1r_1(Pbest_i - X_i) + c_2r_2(Gbest-X_i)
$$
$w$ 为权重向量，取值在 [0,1] 之间，一般采用自适应取值，值越大表示 PSO 全局优化能力越强，迭代越深入，权重值递减，从而使得 PSO 有较强的局部优化能力。

$c_1$ 和 $c_2$ 是学习因子可以理解为加速度常数，一般取 [0,4] 之间。

$r_1$ 和 $r_2$ 是[0,1] 之间的随机数。

*Pbesti* 和 *Gbest* 分别代表粒子 i 的历史最佳位置向量和种群历史最佳位置向量。

**位置向量迭代公式：**
$$
X_i = X_i + V_i
$$
对于粒子群优化算法的运用，主要是对速度和位置向量迭代算子的设计。迭代算子是否有效将决定整个PSO算法性能的优劣，所以如何设计PSO的迭代算子是PSO算法应用的研究重点和难点。

还有自适应版本（Adaptive PSO）和离散版本（discrete）

