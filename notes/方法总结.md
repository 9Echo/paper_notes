## 多目标优化方法总结

### 基本方法概述

1. methods with a priori articulation of preferences：先验偏好

   > 基于先验偏好大致分为加权法和约束法，将多个目标标量化最终转化为单目标优化目标。缺点：单次运算并不能获得整个Pareto最优解集，并且权重值和约束参数难以通过理论说明是否合理。**（这种方法无法体现目标之间的竞争关系）**

   - Weighted global criterion method
   - Weighted sum method
   - Weighted min-max method
   - Lexicographic method
   - Goal programming methods
2. methods with a posteriori articulation of preferences：后验偏好

   > 由于目标之间的偏好因子无法确定，故优先生成一组折衷解，利用偏好信息从中确定最优解

   - 数学方法（精确解）
     - Physical programming
     - Normal boundary intersection (NBI) method
     - Normal constraint (NC) method
   - **近似算法（启发式&元启发式算法）**



**多目标进化算法（Multi-Objective Evolutionary Algorithm，MOEA）**

也叫智能优化算法、元启发式算法 meta-heuristics

> 可以根据是否**利用了Pareto支配关系**分为基于群体的方法、和基于Pareto的方法，其中基于群体的方法（如：VEGA）各个子群之间独立执行进化操作，对于单个子目标的最优解会被抛弃，这种方法基本被淘汰。

优点：单次运算可获得多个解集，且该解集具有良好的收敛性和多样性

缺点：但大部分算法内部应用了随机优化结构，具有一定的不确定性，所以可行解和最优解的偏离程度一般无法被估计。

- 自然进化类算法
  - **遗传算法（GA）衍生算法**

    - VEGA（Vector evaluated genetic algorithm）：无 Pareto 支配关系，各个子群之间独立执行进化操作

    - **NSGA-II**（Elitist Non-dominated Sorting Genetic Algorithms）：提出拥挤度距离度量、保留精英策略

    - MOGA：加入排序机制（基于pareto支配关系）

      - SPEA & **SPEA-II**（strength Pareto evolutionary algorithm）

        提出根据每个个体的支配个体数目和被支配个体数目来进一步计算fitness的值

      - **MOEA/D**：基于分解的思想（传统数学规划方法结合进化算法）

        ​		该算法将通近整个Pareto前沿面的问题分解为一定数量的单目标优化问题,然后用进化算法同时求解这些单目标优化问题. 算法维持一个由每个子问题的当前最优解组成的种群, 子问题之间的近邻关系定义为子问题权重向量之间的距离, 每个子问题的优化过程通过与其近邻子问题之间的进化操作来完成.该算法成功地将数学规划中常用的分解方法引入到进化多目标领域,而且可以直接采用进化算法求解单目标优化问题时的适应度分配和多样性保持策略。

    - PESA & **PESA-II**（Pareto encelope-based selection algorithm）
  - 差分进化算法
  - 免疫算法
    
    - NNIA：基于免疫克隆机制
    
      NNIA模拟了免疫响应中多样性抗体共生 、少数抗体激活的现象, 通过一种基于非支配邻域的个体选择方法, 只选择少数相对孤立的非支配个体作为活性抗体,根据活性抗体的拥挤程度进行比例克隆复制, 对克隆后的抗体群采用了有别于 GA 的重组操作和变异操作, 以此加强对当前Pareto 前沿面中较稀疏区域的搜索.
- 仿生类算法
  - **蚁群算法**（Multi-Objective Ant Colony Optimization, ACO) 2007年提出
  - **粒子群算法**（Multi-Objective Particle Swam Optimization, PSO）2002年提出，应用最为广泛
- 仿物类算法
  
  - **模拟退火算法**
- 人工搜索类算法
  - 禁忌搜索
  - 迭代局部搜索
  - 邻域搜索
- 人工神经网络算法
  - 监督式学习网络
  - 无监督式学习
  - 混合式学习
  - 联想式学习

一般接近实例的案例里面一般都涉及多种算法，先用元启发算法（智能优化算法）求得一个小范围的满意解，再用启发式或者精确算法找最优解，这样既提高效率又能有高质量结果。算法的混合可以发挥各自的优点，抵消其缺点，实现更好的性能。







### 基于京创配载（分货）场景的算法改进思路：

**baseline方法？NGSA-II？MOPSO？**

- 问题：
  - 因为约束条件太多，迭代过程中可能出现种群中所有个体都不符合业务规则导致生成大量甚至几乎都是无效装车清单，迭代优化过程（变异）不稳定
  - 迭代过程效果不好，直接导致局部最优的时间过长，达到最优解的时间更长。
- 解决
  1. **精英个体保留策略**：加入保存每一代局部最优解的额外种群，避免迭代过程中丢失最优/次优解。
  2. **加入更细粒度的排序规则**：在进行种群间个体排序时，不仅仅依靠支配关系，加入其他的rank机制，如体积比较、计算解与解之间的距离。
  3. **引入额外的变异机制**：引导个体搜索种群的最优解，加快算法寻找最优解
  4. 可以在搜索解时引入偏好，从而减少搜索空间（只需要在以往的帕累托平面上找到偏向偏好的那一部分帕累托解即可，不需要完整的帕累托解集）
  5. 利用现有模型的分货结果**替换随机生成的初始种群**。

#### 实验

1. 验证所提出的算法本身可行性（通过调整算法本身的参数）
   - 指标1（收敛性）
   - 指标2（多样性）
2. 验证该指标对各个目标的优化效果
   - 和baseline方法对比
   - 和京创目前的分货结果做对比
   - 和其他方法对比（可不做）

