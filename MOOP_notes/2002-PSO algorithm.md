### PSO粒子群优化算法

**基本思想**

粒子群优化算法是在1995年由Eberhart博士和Kennedy博士一起提出的，它源于对鸟群捕食行为的研究。它的基本核心是利用群体中的个体对信息的共享从而使得整个群体的运动在问题求解空间中产生从无序到有序的演化过程，从而获得问题的最优解。**设想这么一个场景：一群鸟进行觅食，而远处有一片玉米地，所有的鸟都不知道玉米地到底在哪里，但是它们知道自己当前的位置距离玉米地有多远。那么找到玉米地的最佳策略，也是最简单有效的策略就是是搜寻目前距离玉米地最近的鸟群的周围区域**。

在PSO中，每个优化问题的解都是搜索空间中的一只鸟，称之为“粒子”，而问题的最优解就对应为鸟群要寻找的“玉米地”。所有的粒子都具有一个位置向量（粒子在解空间的位置）和速度向量（决定下次飞行的方向和速度），并可以根据目标函数来计算当前的所在位置的适应值（fitness value），可以将其理解为距离“玉米地”的距离。在每次的迭代中，种群中的粒子除了根据**自身的“经验”（历史位置）**进行学习以外，还可以根据种群中**最优粒子的“经验”**来学习，从而确定下一次迭代时需要如何调整和改变飞行的方向和速度。就这样逐步迭代，最终整个种群的粒子就会逐步趋于最优解。

**算法框架**

　　**Step 1** 种群初始化：可以进行随机初始化或者根据被优化的问题设计特定的初始化方法，然后计算个体的适应值，从而选择出个体的局部最优位置向量 *Pbesti* 和种群的全局最优位置向量 *Gbest*。

　　**Step 2** 迭代设置：设置迭代次数 $g_{max}$，并令当前迭代次数 g=1；

　　**Step 3** 速度更新：根据速度向量迭代公式更新每个个体的速度向量；

　　**Step 4** 位置更新：根据位置向量迭代公式更新每个个体的位置向量；

　　**Step 5** 局部位置向量和全局位置向量更新：更新每个个体的 *Pbesti* 和种群的 *Gbest*；

　　**Step 6** 终止条件判断：判断迭代次数时都达到 $g_{max}$，如果满足，输出 *Gbest*；否则继续进行迭代，跳转至**Step 3**。

**速度向量迭代公式：**
$$
V_i = wV_i + c_1r_1(Pbest_i - X_i) + c_2r_2(Gbest-X_i)
$$
$w$ 为权重向量，取值在 [0,1] 之间，一般采用自适应取值，值越大表示 PSO 全局优化能力越强，迭代越深入，权重值递减，从而使得 PSO 有较强的局部优化能力。

$c_1$ 和 $c_2$ 是学习因子可以理解为加速度常数，一般取 [0,4] 之间。

$r_1$ 和 $r_2$ 是[0,1] 之间的随机数。

*Pbesti* 和 *Gbest* 分别代表粒子 i 的历史最佳位置向量和种群历史最佳位置向量。

**位置向量迭代公式：**
$$
X_i = X_i + V_i
$$
对于粒子群优化算法的运用，主要是对速度和位置向量迭代算子的设计。迭代算子是否有效将决定整个PSO算法性能的优劣，所以如何设计PSO的迭代算子是PSO算法应用的研究重点和难点。

还有自适应版本（Adaptive PSO）和离散版本（discrete）



目前来看，粒子群和遗传算法都有多目标的算法。不过遗传算法更多一些，因为粒子群算法更新个体需要全局最优个体，而对于多目标问题，全局最优是不存在的，只有帕累托最优。



粒子群优化主要是靠步长公式，一个是全局优化，一个是局部优化。只要针对这两点就行了。引入时间因素，随着时间变化调整两者的比例。引入个体因素，部分个体倾向于全局，部分个体倾向于局部。引入状态因素，当处于某种状态时优先局部，当某种状态优先全局。



PSO运用到多目标上去的话，出现的问题有以下几点：

1. 如何选择Pbest。我们知道对于单目标优化来说选择Pbest，只需要对比一下就可以选择出哪个较优。但是对于多目标来说两个粒子的对比，并不能对比出哪个好一些。如果粒子的每个目标都要好的话，则该粒子更优。若有些更好，有些更差的话，就无法严格的说哪个好些，哪个差一些。
2. 如何选择Gbest。我们知道对于单目标在种群中只有一个最优的个体。而对于多目标来说，最优的个体有很多个。而对PSO来说，每个粒子只能选择一个作为最优的个体（领带者）。该如何选择呢？

 MOPSO对于第一个问题的做法是在不能严格对比出哪个好一些时随机选择一个其中一个作为历史最优。对于第二个问题，MOPSO则在最优集里面（存档中）根据拥挤程度选择一个领导者。尽量选择不那么密集位置的粒子（在这里用到了网格法）。MOPSO在选择领导者和对存档（也可以说是pareto临时最优断面）进行更新的时候应用了自适应网格法。



### MOPSO

基本步骤：

1. 初始化群体和Archive 集

   给参数赋初值，生成初始群体P1，并把P1 中的非劣解拷贝到Archive 集中得到A1。设当前进化代数为 t，在t 小于总进化代数时完成(2)~(4)的内容。

2. 进化产生下一代群体
   设当前进化的粒子 j，在j 小于群体规模时完成1)~3)的内容。

   1. 计算Archive 集中粒子的密度信息
      把目标空间用网格等分成小区域，以每个区域中包含的粒子数作为粒子的密度信息。粒子所在网格中包含的粒子数越多，其密度值越大，反之越小。
   2. 为群体中的粒子Pj,t 在At 中选择其gBest 粒子gj,tgj,t 粒子的质量决定了MOPSO 算法的收敛性能和非劣解集的多样性，其选择依据是Archive 集中粒子的密度信息。具体地，对于Archive 中的粒子，其密度值越低，选择的概率就越大，反之越小；用Archive 集中的粒子优于群体中的粒子数来评价其搜索潜力，优于群体中的粒子数越多，其搜索潜力越强，反之越弱。
   3. 更新群体中粒子的位置和速度群体中的粒子在gBest 和pBest 的引导下搜索最优解

3. Archive 集的截断操作
   当 Archive 集中的粒子数超过了规定大小时，需要删除多余的个体以维持稳定的Archive 集规模。对于粒子数多于1个的网格k，按式(1)计算该网格中要删除的粒子数PN，然后在网格k 中，随机删除PN 个粒子。

4. 输出Archive 集中的粒子信息

